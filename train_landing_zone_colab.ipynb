{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0af2cd",
   "metadata": {},
   "source": [
    "# Landing Zone Detection with RF-DETR\n",
    "## CS4824 Final Project - Google Colab Training Notebook\n",
    "\n",
    "This notebook trains an RF-DETR model to detect landing zones from Blender-rendered frames.\n",
    "\n",
    "### Instructions:\n",
    "1. Run this notebook with GPU enabled: Runtime → Change runtime type → GPU (T4)\n",
    "2. The notebook will clone the GitHub repo, unzip the dataset, and train the model\n",
    "3. After training, the model will be saved to Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adea41c",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, check GPU availability and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9ddb7",
   "metadata": {},
   "source": [
    "## 2. Clone GitHub Repository\n",
    "\n",
    "Clone the project repository containing the dataset and scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GitHub repository\n",
    "!git clone https://github.com/PieLord757/CS4824FinalProject.git\n",
    "%cd CS4824FinalProject\n",
    "\n",
    "# List contents\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4d248",
   "metadata": {},
   "source": [
    "## 3. Unzip Dataset & Install RF-DETR\n",
    "\n",
    "Extract the COCO dataset and install the RF-DETR library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d177c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = 'coco-dataset.zip'\n",
    "extract_path = '.'\n",
    "\n",
    "print(\"Extracting dataset...\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "print(\"✓ Dataset extracted!\")\n",
    "\n",
    "# Verify extraction\n",
    "dataset_path = 'coco-dataset'\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"✓ Dataset directory exists: {dataset_path}\")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = os.path.join(dataset_path, split)\n",
    "        if os.path.exists(split_path):\n",
    "            num_files = len(os.listdir(split_path))\n",
    "            print(f\"  {split}: {num_files} files\")\n",
    "else:\n",
    "    print(\"✗ Dataset extraction failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047c90b",
   "metadata": {},
   "source": [
    "## 4. Install RF-DETR\n",
    "\n",
    "Clone and install the RF-DETR library from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c699fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install RF-DETR\n",
    "!pip install rfdetr\n",
    "\n",
    "print(\"\\n✓ RF-DETR installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cbe87",
   "metadata": {},
   "source": [
    "## 5. Verify Dataset Structure\n",
    "\n",
    "Check that the COCO dataset is properly structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Check dataset structure\n",
    "dataset_path = \"coco-dataset\"\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    level = root.replace(dataset_path, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:5]:  # Show first 5 files\n",
    "        print(f\"{subindent}{file}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"{subindent}... and {len(files) - 5} more files\")\n",
    "\n",
    "# Check annotation files\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    anno_file = f\"{dataset_path}/{split}/_annotations.coco.json\"\n",
    "    if os.path.exists(anno_file):\n",
    "        with open(anno_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"\\n{split.upper()} split:\")\n",
    "        print(f\"  Images: {len(data['images'])}\")\n",
    "        print(f\"  Annotations: {len(data['annotations'])}\")\n",
    "        print(f\"  Categories: {data['categories']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f950e",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Images\n",
    "\n",
    "Display some training images with their bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Load training annotations\n",
    "with open('coco-dataset/train/_annotations.coco.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "# Create image_id to annotations mapping\n",
    "img_to_annos = {}\n",
    "for anno in train_data['annotations']:\n",
    "    img_id = anno['image_id']\n",
    "    if img_id not in img_to_annos:\n",
    "        img_to_annos[img_id] = []\n",
    "    img_to_annos[img_id].append(anno)\n",
    "\n",
    "# Display first 6 images with annotations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_info in enumerate(train_data['images'][:6]):\n",
    "    img_path = f\"coco-dataset/train/{img_info['file_name']}\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    if img_info['id'] in img_to_annos:\n",
    "        for anno in img_to_annos[img_info['id']]:\n",
    "            x, y, w, h = anno['bbox']\n",
    "            rect = Rectangle((x, y), w, h, linewidth=2, edgecolor='lime', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_title(f\"{img_info['file_name']}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6f4f9",
   "metadata": {},
   "source": [
    "## 7. Train the RF-DETR Model\n",
    "\n",
    "Train the model using the RF-DETR library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rfdetr import RFDETRNano\n",
    "\n",
    "def train_landing_zone_model():\n",
    "    \"\"\"Train RF-DETR model for landing zone detection\"\"\"\n",
    "    \n",
    "    dataset_path = \"coco-dataset\"\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Initializing RF-DETR Nano model...\")\n",
    "    model = RFDETRNano()\n",
    "    \n",
    "    print(f\"\\nTraining Configuration:\")\n",
    "    print(f\"  Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "    print(f\"  Dataset: {dataset_path}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting training...\")\n",
    "    model.train(\n",
    "        dataset_dir=dataset_path,\n",
    "        epochs=100,\n",
    "        batch_size=8,\n",
    "        grad_accum_steps=4,\n",
    "        lr=1e-4\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✓ Training completed!\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Run training\n",
    "model = train_landing_zone_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4add3e",
   "metadata": {},
   "source": [
    "## 8. Check Training Outputs\n",
    "\n",
    "List the model checkpoints saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for training outputs\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Find .pth files (model checkpoints)\n",
    "pth_files = glob.glob(\"**/*.pth\", recursive=True)\n",
    "print(\"Model checkpoints found:\")\n",
    "for f in pth_files:\n",
    "    size = os.path.getsize(f) / (1024*1024)\n",
    "    print(f\"  {f} ({size:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b61c3c",
   "metadata": {},
   "source": [
    "## 9. Test Inference\n",
    "\n",
    "Run inference on test images to see model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a233c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on sample images\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get test images\n",
    "test_dir = \"coco-dataset/test\"\n",
    "test_images = [f for f in os.listdir(test_dir) if f.endswith('.png')][:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_name in enumerate(test_images):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    \n",
    "    # Run inference\n",
    "    detections = model.predict(img_path, threshold=0.3)\n",
    "    \n",
    "    # Load and display image\n",
    "    img = Image.open(img_path)\n",
    "    ax = axes[idx]\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Draw detections\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det.xyxy\n",
    "        conf = det.confidence\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                             linewidth=2, edgecolor='red', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1-5, f\"{conf:.2f}\", color='red', fontsize=10, weight='bold')\n",
    "    \n",
    "    ax.set_title(img_name)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beba7b6",
   "metadata": {},
   "source": [
    "## 10. Save Model to Google Drive\n",
    "\n",
    "Mount Google Drive and save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e707b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save the model\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Save model to Drive\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "drive_output = \"/content/drive/MyDrive/landing_zone_model\"\n",
    "os.makedirs(drive_output, exist_ok=True)\n",
    "\n",
    "# Find and copy model files\n",
    "pth_files = glob.glob(\"**/*.pth\", recursive=True)\n",
    "for pth_file in pth_files:\n",
    "    dst = os.path.join(drive_output, os.path.basename(pth_file))\n",
    "    shutil.copy2(pth_file, dst)\n",
    "    print(f\"✓ Saved: {os.path.basename(pth_file)}\")\n",
    "\n",
    "print(f\"\\n✓ Model saved to Google Drive: {drive_output}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
